{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importer les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lien vers les différents DATASETS que propose PyTorch : https://pytorch.org/vision/stable/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:00<00:00, 42559790.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 1549275.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4422102/4422102 [00:00<00:00, 23547595.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 15357238.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous passons le Dataset en tant qu'argument au DataLoader. Cela encapsule un itérable sur notre ensemble de données et prend en charge le batch automatique, l'échantillonnage, le mélange aléatoire (shuffling) et le chargement de données avec plusieurs processus. Ici, nous définissons une taille de batch de 64, c'est-à-dire que chaque élément dans l'itérable du DataLoader renverra un batch de 64 caractéristiques et étiquettes.\n",
    "\n",
    "- DataLoader : C'est un outil qui facilite la gestion de vos données en les organisant en lots (batches). Cela permet de charger les données plus efficacement et de les préparer pour l'entraînement.\n",
    "\n",
    "- Batch automatique : Plutôt que de traiter les exemples un par un, le DataLoader regroupe plusieurs exemples dans un lot, ce qui améliore l'efficacité de l'entraînement, en particulier avec du calcul parallèle.\n",
    "\n",
    "- Sampling (échantillonnage) : C'est la manière dont les données sont choisies dans l'ensemble de données. Par exemple, on peut échantillonner de manière aléatoire ou selon certaines règles.\n",
    "\n",
    "- Shuffling (mélange aléatoire) : Avant de former les lots, les données peuvent être mélangées pour éviter que le modèle ne s'adapte à un ordre spécifique des données.\n",
    "\n",
    "Caractéristiques : \n",
    "\n",
    "- N (Batch Size) : Le nombre d'exemples ou d'images dans un batch. C'est le nombre total d'éléments que le modèle traite simultanément pendant une itération.\n",
    "\n",
    "- C (Channels) : Le nombre de canaux dans les données. \n",
    "\n",
    "- H (Height) : La hauteur de l'image (le nombre de pixels verticaux). \n",
    "\n",
    "- W (Width) : La largeur de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, \n",
    "                              batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, \n",
    "                             batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Créer un model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour définir un réseau de neurones dans PyTorch, nous créons une classe qui hérite de nn.Module. Nous définissons les couches du réseau dans la fonction init et spécifions comment les données passeront à travers le réseau dans la fonction forward. Pour accélérer les opérations dans le réseau de neurones, nous le déplaçons sur le GPU ou le MPS si disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):    #structure de base pour tous les modèles de réseaux de neurones dans PyTorch\n",
    "    def __init__(self):\n",
    "        super().__init__()    #On appelle super().__init__() pour s'assurer que toutes les fonctionnalités de nn.Module sont initialisées correctement\n",
    "        self.flatten = nn.Flatten()    #couche de flattening (aplatissement) qui prend une image en entrée (par exemple, de dimensions 28x28 pixels) \n",
    "                                        #et la convertit en un vecteur 1D (de 28*28=784 éléments)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),    #couche fully connected avec 784 entrées (correspondant à l'image aplatie) et 512 sorties\n",
    "            nn.ReLU(),    #Fonction d'activation ReLU\n",
    "            nn.Linear(512, 512),    #Une autre couche fully connected avec 512 entrées et 512 sorties\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)    #La couche de sortie avec 512 entrées et 10 sorties. Ici, 10 est le nombre de classes pour la classification (par exemple, 10 classes pour des chiffres de 0 à 9 dans le dataset MNIST).\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits    #retourne les logits, c'est-à-dire les sorties non normalisées du modèle. \n",
    "\n",
    "#Ces logits peuvent être ensuite transformés (par exemple avec une softmax) pour obtenir des probabilités lors de la classification\n",
    "\n",
    "# crée une instance du modèle NeuralNetwork et on déplace ce modèle vers l'appareil (CPU ou GPU) spécifié par device\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintenant on souhaite optimiser les paramètres du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
